{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef390f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    average_precision_score, accuracy_score\n",
    ")\n",
    "import sklearn\n",
    "from packaging import version\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "np.set_printoptions(suppress=True)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76355be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ohe():\n",
    "    if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    else:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def calibrate_prefit(prefit_estimator, X_valid, y_valid, method=\"isotonic\"):\n",
    "    if version.parse(sklearn.__version__) >= version.parse(\"1.4\"):\n",
    "        cal = CalibratedClassifierCV(estimator=prefit_estimator, method=method, cv=\"prefit\")\n",
    "    else:\n",
    "        cal = CalibratedClassifierCV(base_estimator=prefit_estimator, method=method, cv=\"prefit\")\n",
    "    cal.fit(X_valid, y_valid)\n",
    "    return cal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247283cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA = r\"C:\\Users\\habib\\OneDrive\\المستندات\\Graduation Project\\GRAD-proj-DEPI\\DS1\\Cardiovascular Diseases Risk Prediction Dataset export 2025-10-15 21-12-56.csv\"\n",
    "df = pd.read_csv(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe483537",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = [c for c in [\n",
    "    \"General_Health\",\"Checkup\",\"Exercise\",\"Skin_Cancer\",\"Other_Cancer\",\n",
    "    \"Depression\",\"Diabetes\",\"Arthritis\",\"Sex\",\"Age_Category\",\"Smoking_History\",\n",
    "    \"BMI_Category\"\n",
    "] if c in df.columns]\n",
    "\n",
    "NUM = [c for c in [\n",
    "    \"Height_(cm)\",\"Weight_(kg)\",\"BMI\",\"Alcohol_Consumption\",\n",
    "    \"Fruit_Consumption\",\"Green_Vegetables_Consumption\",\"FriedPotato_Consumption\"\n",
    "] if c in df.columns]\n",
    "\n",
    "TARGET = \"Heart_Disease\"\n",
    "#Ensure target is numeric 0/1\n",
    "if df[TARGET].dtype==\"O\":\n",
    "    df[TARGET] = df[TARGET].map({\"Yes\":1,\"No\":0}).astype(int)\n",
    "\n",
    "X = df[CAT + NUM].copy()\n",
    "y = df[TARGET].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46a7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data Splitting\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c82835db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', make_ohe()) \n",
    "])\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "('imputer', SimpleImputer(strategy='median')),\n",
    "('scaler', StandardScaler())\n",
    "])\n",
    "preprocess = ColumnTransformer(\n",
    "transformers=[('cat', cat_transformer, CAT), ('num', num_transformer, NUM)],\n",
    "remainder='drop',\n",
    "verbose_feature_names_out=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b59f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(pipe, name):\n",
    "    \"\"\"Train on full train set and evaluate on test set (binary).\"\"\"\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Binary ROC-AUC using positive-class probabilities when available\n",
    "    try:\n",
    "        y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "        roc = roc_auc_score(y_test, y_proba)\n",
    "    except Exception:\n",
    "        roc = np.nan\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"{name} — Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Accuracy:\", f\"{acc:.3f}\")\n",
    "    print(\"ROC-AUC:\", \"NA\" if np.isnan(roc) else f\"{roc:.3f}\")\n",
    "    return acc, roc\n",
    "\n",
    "def cv_prob_metrics(pipe, X, y, name, n_splits=5):\n",
    "    \"\"\"Cross-validated ROC-AUC and PR-AUC on training data.\"\"\"\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    y_oof_proba = cross_val_predict(pipe, X, y, cv=cv, method='predict_proba')[:,1]\n",
    "    \n",
    "    roc = roc_auc_score(y, y_oof_proba)\n",
    "    pr = average_precision_score(y, y_oof_proba)\n",
    "    \n",
    "    print(f\"{name} — CV ROC-AUC: {roc:.3f}, CV PR-AUC: {pr:.3f}\")\n",
    "    return roc, pr, y_oof_proba\n",
    "\n",
    "def calibrate_on_valid(pipe, X_valid, y_valid, method='isotonic'):\n",
    "    \"\"\"Calibrate predicted probabilities on validation set.\"\"\"\n",
    "    calib = CalibratedClassifierCV(pipe, method=method, cv='prefit')\n",
    "    calib.fit(X_valid, y_valid)\n",
    "    return calib\n",
    "\n",
    "def pick_threshold_by_f1(probs, y_true=None):\n",
    "    from sklearn.metrics import f1_score\n",
    "    if y_true is None:\n",
    "        y_true = y_valid\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    f1_scores = [f1_score(y_true, probs >= t) for t in thresholds]\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    return thresholds[best_idx]\n",
    "\n",
    "\n",
    "def eval_on_test(calib, tau, name):\n",
    "    \"\"\"Evaluate calibrated model on test set with selected threshold.\"\"\"\n",
    "    y_proba = calib.predict_proba(X_test)[:,1]\n",
    "    y_pred = (y_proba >= tau).astype(int)\n",
    "    \n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} — Test Evaluation:\")\n",
    "    print(f\"Threshold: {tau:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.3f}, ROC-AUC: {roc:.3f}, PR-AUC: {pr:.3f}\")\n",
    "    \n",
    "    return {'accuracy': acc, 'roc_auc': roc, 'pr_auc': pr, 'threshold': tau}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9367e",
   "metadata": {},
   "source": [
    "`Interpretation:`\n",
    "\n",
    "Precision: of all patients predicted to have class X, how many actually had it.\n",
    "\n",
    "Recall: of all patients who truly had class X, how many did the model find.\n",
    "\n",
    "F1-score: a balance between precision and recall.\n",
    "\n",
    "Support: how many samples of that class exist in the test set.\n",
    "\n",
    "Accuracy: overall correct predictions / total samples.\n",
    "\n",
    "Macro average: average of all classes equally.\n",
    "\n",
    "Weighted average: average weighted by class sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6370f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC-AUC: 0.8337879132218997\n",
      "CV PR-AUC: 0.3051473957296993\n"
     ]
    }
   ],
   "source": [
    "# Model candidates (start with LogisticRegression; you can swap in XGBoost/LightGBM)\n",
    "logistic_clf = LogisticRegression(\n",
    "    max_iter=4000, class_weight='balanced', n_jobs=None)\n",
    "lr_pipe = ImbPipeline(\n",
    "    steps=[('prep', preprocess),('clf', logistic_clf)])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_tr_oof_proba = cross_val_predict(lr_pipe, X_train, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "\n",
    "print(\"CV ROC-AUC:\", roc_auc_score(y_train, y_tr_oof_proba))\n",
    "print(\"CV PR-AUC:\", average_precision_score(y_train, y_tr_oof_proba))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b9c21",
   "metadata": {},
   "source": [
    "**Define model pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8392102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\"LogisticRegression\": Pipeline([('prep', preprocess),\n",
    "('clf', LogisticRegression(max_iter=4000, class_weight='balanced'))]),\n",
    "\"NaiveBayes\": Pipeline([('prep', preprocess),\n",
    "('clf', GaussianNB())]),\n",
    "\"KNN\": Pipeline([('prep', preprocess),\n",
    "('clf', KNeighborsClassifier(n_neighbors=15))]),\n",
    "\"DecisionTree\": Pipeline([('prep', preprocess),\n",
    "('clf', DecisionTreeClassifier(max_depth=6, class_weight='balanced', random_state=RANDOM_STATE))]),\n",
    "\"RandomForest\": Pipeline([('prep', preprocess),\n",
    "('clf', RandomForestClassifier(n_estimators=400, max_depth=None, min_samples_leaf=2,\n",
    "class_weight='balanced_subsample', n_jobs=-1, random_state=RANDOM_STATE))]),\n",
    "\"XGB\": Pipeline([('prep', preprocess),\n",
    "('clf', XGBClassifier(\n",
    "n_estimators=600, max_depth=4, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "reg_lambda=1.0, reg_alpha=0.0, eval_metric='logloss', n_jobs=-1, random_state=RANDOM_STATE\n",
    "))]),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f7d02",
   "metadata": {},
   "source": [
    "**Train, calibrate, evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48334be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== LogisticRegression ====\n",
      "LogisticRegression — CV ROC-AUC: 0.834, CV PR-AUC: 0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression — Test Evaluation:\n",
      "Threshold: 0.170\n",
      "Accuracy: 0.852, ROC-AUC: 0.840, PR-AUC: 0.308\n",
      "\n",
      "==== NaiveBayes ====\n",
      "NaiveBayes — CV ROC-AUC: 0.800, CV PR-AUC: 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaiveBayes — Test Evaluation:\n",
      "Threshold: 0.160\n",
      "Accuracy: 0.830, ROC-AUC: 0.810, PR-AUC: 0.264\n",
      "\n",
      "==== KNN ====\n",
      "KNN — CV ROC-AUC: 0.761, CV PR-AUC: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN — Test Evaluation:\n",
      "Threshold: 0.130\n",
      "Accuracy: 0.830, ROC-AUC: 0.772, PR-AUC: 0.228\n",
      "\n",
      "==== DecisionTree ====\n",
      "DecisionTree — CV ROC-AUC: 0.782, CV PR-AUC: 0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTree — Test Evaluation:\n",
      "Threshold: 0.150\n",
      "Accuracy: 0.834, ROC-AUC: 0.791, PR-AUC: 0.254\n",
      "\n",
      "==== RandomForest ====\n",
      "RandomForest — CV ROC-AUC: 0.821, CV PR-AUC: 0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest — Test Evaluation:\n",
      "Threshold: 0.160\n",
      "Accuracy: 0.845, ROC-AUC: 0.829, PR-AUC: 0.292\n",
      "\n",
      "==== XGB ====\n",
      "XGB — CV ROC-AUC: 0.835, CV PR-AUC: 0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB — Test Evaluation:\n",
      "Threshold: 0.180\n",
      "Accuracy: 0.866, ROC-AUC: 0.842, PR-AUC: 0.312\n",
      "\n",
      "Best model by PR-AUC: XGB {'accuracy': 0.8664551360918648, 'roc_auc': 0.8415844743469426, 'pr_auc': 0.31201809082741294, 'threshold': np.float64(0.18000000000000002)}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "best_name, best_pr = None, -np.inf\n",
    "calibrated_models = {}\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    print(\"\\n====\", name, \"====\")\n",
    "    \n",
    "    # Cross-validated metrics on training set\n",
    "    roc, pr, _ = cv_prob_metrics(pipe, X_train, y_train, name)\n",
    "    \n",
    "    # Fit on full training set\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibrate on validation set\n",
    "    calib = calibrate_on_valid(pipe, X_valid, y_valid, method='isotonic')\n",
    "    \n",
    "    # Pick best threshold on validation\n",
    "    p_valid = calib.predict_proba(X_valid)[:,1]\n",
    "    tau = pick_threshold_by_f1(p_valid, y_valid)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    metrics = eval_on_test(calib, tau, name)\n",
    "    results[name] = metrics\n",
    "    calibrated_models[name] = (calib, tau)\n",
    "    \n",
    "    # Track best model by PR-AUC\n",
    "    if metrics['pr_auc'] > best_pr:\n",
    "        best_pr = metrics['pr_auc']\n",
    "        best_name = name\n",
    "\n",
    "print(\"\\nBest model by PR-AUC:\", best_name, results[best_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaae9a0",
   "metadata": {},
   "source": [
    "| Model               | Threshold | Accuracy | ROC-AUC | PR-AUC |\n",
    "| ------------------- | --------- | -------- | ------- | ------ |\n",
    "| Logistic Regression | 0.170     | 0.852    | 0.840   | 0.308  |\n",
    "| Naive Bayes         | 0.160     | 0.830    | 0.810   | 0.264  |\n",
    "| KNN                 | 0.130     | 0.830    | 0.772   | 0.228  |\n",
    "| Decision Tree      | 0.150     | 0.834     | 0.791     | 0.254     | Easily interpretable, but prone to overfitting and limited generalization. |\n",
    "| Random Forest     | 0.160     | 0.845     | 0.829     | 0.292     | Stronger ensemble; more stable and less overfitted than a single tree.     |\n",
    "| XGBoost (XGB)       | 0.180     | **0.866** | **0.842** | **0.312** | Best performer overall; excellent tradeoff between accuracy and PR-AUC.  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61283a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC (fast alternative to SVC-RBF)\n",
    "svc_pipe = Pipeline([\n",
    "    ('prep', preprocess),                     # Preprocessing: scaling & encoding\n",
    "    ('clf', LinearSVC(max_iter=5000))        # Linear SVM\n",
    "])\n",
    "# LinearSVC + SMOTE (handle imbalance)\n",
    "svc_smote_pipe = ImbPipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', LinearSVC(max_iter=5000))\n",
    "])\n",
    "\n",
    "# Models dictionary\n",
    "models = {\n",
    "    'LinearSVC': svc_pipe,\n",
    "    'LinearSVC + SMOTE': svc_smote_pipe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9805f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== LinearSVC ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== LinearSVC + SMOTE ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC — selected threshold: 0.190\n",
      "LinearSVC + SMOTE — selected threshold: 0.180\n"
     ]
    }
   ],
   "source": [
    "calibrated_models = {}\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\n==== {name} ====\")\n",
    "    \n",
    "    # Fit on full training set\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibrate probabilities (LinearSVC does not provide predict_proba by default)\n",
    "    calib = CalibratedClassifierCV(pipe, method='isotonic', cv='prefit')\n",
    "    calib.fit(X_valid, y_valid)\n",
    "    \n",
    "    # Store calibrated model\n",
    "    calibrated_models[name] = calib\n",
    "\n",
    "def pick_threshold_by_f1(probs, y_true):\n",
    "    from sklearn.metrics import f1_score\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    f1_scores = [f1_score(y_true, probs >= t) for t in thresholds]\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    return thresholds[best_idx]\n",
    "\n",
    "thresholds = {}\n",
    "for name, calib in calibrated_models.items():\n",
    "    p_valid = calib.predict_proba(X_valid)[:,1]\n",
    "    tau = pick_threshold_by_f1(p_valid, y_valid)\n",
    "    thresholds[name] = tau\n",
    "    print(f\"{name} — selected threshold: {tau:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec75232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinearSVC — Test Evaluation:\n",
      "Threshold: 0.190\n",
      "Accuracy: 0.865, ROC-AUC: 0.838, PR-AUC: 0.309\n",
      "\n",
      "LinearSVC + SMOTE — Test Evaluation:\n",
      "Threshold: 0.180\n",
      "Accuracy: 0.861, ROC-AUC: 0.838, PR-AUC: 0.304\n",
      "\n",
      "Best model by PR-AUC: LinearSVC {'accuracy': 0.8645340931166224, 'roc_auc': 0.8376281920654465, 'pr_auc': 0.3089954469723619, 'threshold': np.float64(0.19)}\n"
     ]
    }
   ],
   "source": [
    "def eval_on_test(calib, tau, name):\n",
    "    y_proba = calib.predict_proba(X_test)[:,1]\n",
    "    y_pred = (y_proba >= tau).astype(int)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    \n",
    "    print(f\"\\n{name} — Test Evaluation:\")\n",
    "    print(f\"Threshold: {tau:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.3f}, ROC-AUC: {roc:.3f}, PR-AUC: {pr:.3f}\")\n",
    "    \n",
    "    return {'accuracy': acc, 'roc_auc': roc, 'pr_auc': pr, 'threshold': tau}\n",
    "\n",
    "results = {}\n",
    "for name, calib in calibrated_models.items():\n",
    "    tau = thresholds[name]\n",
    "    results[name] = eval_on_test(calib, tau, name)\n",
    "\n",
    "# =========================\n",
    "# Best model by PR-AUC\n",
    "# =========================\n",
    "best_name = max(results, key=lambda k: results[k]['pr_auc'])\n",
    "print(\"\\nBest model by PR-AUC:\", best_name, results[best_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ffd29",
   "metadata": {},
   "source": [
    "| Model             | Threshold | Accuracy | ROC-AUC | PR-AUC |\n",
    "| ----------------- | --------- | -------- | ------- | ------ |\n",
    "| LinearSVC         | 0.190     | 0.865    | 0.838   | 0.309  |\n",
    "| LinearSVC + SMOTE | 0.180     | 0.861    | 0.838   | 0.304  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d419db",
   "metadata": {},
   "source": [
    "| Model                   | Threshold | Accuracy  | ROC-AUC   | PR-AUC    | Key Insights                                                               |\n",
    "| ----------------------- | --------- | --------- | --------- | --------- | -------------------------------------------------------------------------- |\n",
    "| **Logistic Regression** | 0.170     | 0.852     | 0.840     | 0.308     | Stable baseline; well-calibrated probabilities and balanced performance.   |\n",
    "| **Naive Bayes**         | 0.160     | 0.830     | 0.810     | 0.264     | Fast, interpretable model but weaker precision-recall on minority class.   |\n",
    "| **KNN**                 | 0.130     | 0.830     | 0.772     | 0.228     | Simpler method; struggles with complex/nonlinear boundaries.               |\n",
    "| **LinearSVC**           | 0.190     | 0.865     | 0.838     | 0.309     | High accuracy and PR-AUC; efficient for large datasets.                    |\n",
    "| **LinearSVC + SMOTE**   | 0.180     | 0.861     | 0.838     | 0.304     | Oversampling slightly improves recall, minor PR-AUC drop.                  |\n",
    "| **Decision Tree**       | 0.150     | 0.834     | 0.791     | 0.254     | Easily interpretable, but prone to overfitting and limited generalization. |\n",
    "| **Random Forest**       | 0.160     | 0.845     | 0.829     | 0.292     | Stronger ensemble; more stable and less overfitted than a single tree.     |\n",
    "| **XGBoost (XGB)**       | 0.180     | **0.866** | **0.842** | **0.312** | Best performer overall; excellent tradeoff between accuracy and PR-AUC.  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274e475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ff583b3",
   "metadata": {},
   "source": [
    "**hyperparameter tuning for top candidates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05dc5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# top_to_tune = ['XGB', 'LinearSVC + SMOTE', 'LinearSVC', 'LogisticRegression']\n",
    "\n",
    "# for name in top_to_tune:\n",
    "#     if name not in models:\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\nGridSearch for {name}\")\n",
    "#     base = models[name]\n",
    "\n",
    "#     if name == 'LinearSVC':\n",
    "#         param_grid = {\n",
    "#             'clf__C': [0.5, 1, 2, 4],\n",
    "#             'clf__loss': ['hinge', 'squared_hinge'],\n",
    "#             'clf__max_iter': [2000, 4000]\n",
    "#         }\n",
    "\n",
    "#     elif name == 'LinearSVC + SMOTE':\n",
    "#         param_grid = {\n",
    "#             'clf__C': [0.5, 1, 2],\n",
    "#             'clf__loss': ['hinge', 'squared_hinge'],\n",
    "#             'clf__max_iter': [2000, 4000]\n",
    "#         }\n",
    "\n",
    "#     elif name == 'LogisticRegression':\n",
    "#         param_grid = {\n",
    "#             'clf__C': [0.5, 1, 2, 4],\n",
    "#             'clf__penalty': ['l2'],\n",
    "#             'clf__solver': ['lbfgs'],\n",
    "#             'clf__max_iter': [2000, 4000]\n",
    "#         }\n",
    "\n",
    "#     # GridSearchCV for PR-AUC (minority sensitivity)\n",
    "#     gs = GridSearchCV(\n",
    "#         estimator=base,\n",
    "#         param_grid=param_grid,\n",
    "#         scoring='average_precision',\n",
    "#         cv=cv,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     # Fit on training data\n",
    "#     gs.fit(X_train, y_train)\n",
    "\n",
    "#     print(\" Best params:\", gs.best_params_)\n",
    "#     print(\" Best PR-AUC (CV):\", round(gs.best_score_, 4))\n",
    "\n",
    "#     # Refit and calibrate\n",
    "#     best_pipe = gs.best_estimator_\n",
    "#     calib = calibrate_on_valid(best_pipe, X_valid, y_valid, method='isotonic')\n",
    "\n",
    "#     # Optimize threshold by F1 score\n",
    "#     p_valid = calib.predict_proba(X_valid)[:, 1]\n",
    "#     tau = pick_threshold_by_f1(p_valid, y_valid)\n",
    "\n",
    "#     # Final test evaluation\n",
    "#     tuned_metrics = eval_on_test(calib, tau, f\"{name}_Tuned\")\n",
    "#     results[f\"{name}_Tuned\"] = tuned_metrics\n",
    "#     calibrated_models[f\"{name}_Tuned\"] = (calib, tau)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f5fb62",
   "metadata": {},
   "source": [
    "**Grid search is very slow**\n",
    "- GridSearchCV tests every combination in param_grid.\n",
    "\n",
    "- If cv=5, and 4×2×2 combinations → that’s 16×5 = 80 model fits per model.\n",
    "\n",
    "- Doing that for 3–4 models is hundreds of fits.\n",
    "\n",
    "- LinearSVC is slow (non-probabilistic, iterative convergence).\n",
    "\n",
    "- XGB by default uses CPU-based tree building, which is slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b4d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c154ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habib\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [23:12:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost pipeline retrained WITHOUT add_feats!\n",
      "Saved: Models/stage1_xgb_20251129_231213.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib, time, os\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# لا نستخدم FunctionTransformer ولا add_feats إطلاقاً\n",
    "xgb_pipe = ImbPipeline([\n",
    "    (\"pre\", preprocess),   # نفس الـ preprocess اللي عندك\n",
    "    (\"clf\", XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipe.fit(X, y)\n",
    "print(\"XGBoost pipeline retrained WITHOUT add_feats!\")\n",
    "\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "joblib.dump(xgb_pipe, f\"Models/stage1_xgb_{ts}.joblib\")\n",
    "joblib.dump(xgb_pipe, \"Models/stage1_xgb_latest.joblib\")\n",
    "print(\"Saved:\", f\"Models/stage1_xgb_{ts}.joblib\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5bff1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>max_prob</th>\n",
       "      <th>entropy</th>\n",
       "      <th>margin</th>\n",
       "      <th>stage1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18467</th>\n",
       "      <td>18467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967996</td>\n",
       "      <td>0.032004</td>\n",
       "      <td>0.967996</td>\n",
       "      <td>0.141640</td>\n",
       "      <td>0.935993</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190998</th>\n",
       "      <td>190998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961581</td>\n",
       "      <td>0.038419</td>\n",
       "      <td>0.961581</td>\n",
       "      <td>0.162886</td>\n",
       "      <td>0.923163</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201522</th>\n",
       "      <td>201522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778115</td>\n",
       "      <td>0.221885</td>\n",
       "      <td>0.778115</td>\n",
       "      <td>0.529284</td>\n",
       "      <td>0.556229</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302375</th>\n",
       "      <td>302375</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983880</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.983880</td>\n",
       "      <td>0.082528</td>\n",
       "      <td>0.967760</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84071</th>\n",
       "      <td>84071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980228</td>\n",
       "      <td>0.019772</td>\n",
       "      <td>0.980228</td>\n",
       "      <td>0.097149</td>\n",
       "      <td>0.960456</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296879</th>\n",
       "      <td>296879</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.031717</td>\n",
       "      <td>0.989910</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107694</th>\n",
       "      <td>107694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713193</td>\n",
       "      <td>0.286807</td>\n",
       "      <td>0.713193</td>\n",
       "      <td>0.599268</td>\n",
       "      <td>0.426387</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115683</th>\n",
       "      <td>115683</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989675</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.989675</td>\n",
       "      <td>0.057489</td>\n",
       "      <td>0.979350</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140830</th>\n",
       "      <td>140830</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853519</td>\n",
       "      <td>0.146481</td>\n",
       "      <td>0.853519</td>\n",
       "      <td>0.416556</td>\n",
       "      <td>0.707038</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285090</th>\n",
       "      <td>285090</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.126745</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.746511</td>\n",
       "      <td>2025-11-29 23:12:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  pred_class        p0        p1  max_prob   entropy  \\\n",
       "18467       18467           0  0.967996  0.032004  0.967996  0.141640   \n",
       "190998     190998           0  0.961581  0.038419  0.961581  0.162886   \n",
       "201522     201522           0  0.778115  0.221885  0.778115  0.529284   \n",
       "302375     302375           0  0.983880  0.016120  0.983880  0.082528   \n",
       "84071       84071           0  0.980228  0.019772  0.980228  0.097149   \n",
       "296879     296879           0  0.994955  0.005045  0.994955  0.031717   \n",
       "107694     107694           0  0.713193  0.286807  0.713193  0.599268   \n",
       "115683     115683           0  0.989675  0.010325  0.989675  0.057489   \n",
       "140830     140830           0  0.853519  0.146481  0.853519  0.416556   \n",
       "285090     285090           0  0.873255  0.126745  0.873255  0.380151   \n",
       "\n",
       "          margin            stage1_ts  \n",
       "18467   0.935993  2025-11-29 23:12:13  \n",
       "190998  0.923163  2025-11-29 23:12:13  \n",
       "201522  0.556229  2025-11-29 23:12:13  \n",
       "302375  0.967760  2025-11-29 23:12:13  \n",
       "84071   0.960456  2025-11-29 23:12:13  \n",
       "296879  0.989910  2025-11-29 23:12:13  \n",
       "107694  0.426387  2025-11-29 23:12:13  \n",
       "115683  0.979350  2025-11-29 23:12:13  \n",
       "140830  0.707038  2025-11-29 23:12:13  \n",
       "285090  0.746511  2025-11-29 23:12:13  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Prediction helper ---\n",
    "def stage1_predict_contract(model, df_rows, id_col=None):\n",
    "    \"\"\"\n",
    "    Predicts class, probabilities, max probability, entropy, and margin.\n",
    "    df_rows: dataframe with same features used for training.\n",
    "    \"\"\"\n",
    "    P = model.predict_proba(df_rows)              # shape (n, classes)\n",
    "    yhat = P.argmax(axis=1)\n",
    "    max_prob = P.max(axis=1)\n",
    "    \n",
    "    # entropy\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ent = -(P * np.log(P + 1e-12)).sum(axis=1)\n",
    "    \n",
    "    # margin: top - second\n",
    "    sortedP = np.sort(P, axis=1)[:, ::-1]\n",
    "    margin = sortedP[:,0] - sortedP[:,1]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"pred_class\": yhat,\n",
    "        **{f\"p{i}\": P[:,i] for i in range(P.shape[1])},\n",
    "        \"max_prob\": max_prob,\n",
    "        \"entropy\": ent,\n",
    "        \"margin\": margin,\n",
    "        \"stage1_ts\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }, index=df_rows.index)\n",
    "\n",
    "    if id_col and id_col in df_rows.columns:\n",
    "        out.insert(0, \"patient_id\", df_rows[id_col].values)\n",
    "    else:\n",
    "        out.insert(0, \"patient_id\", df_rows.index.astype(str))\n",
    "\n",
    "    return out\n",
    "\n",
    "# --- Example usage ---\n",
    "stage1_contract_test = stage1_predict_contract(xgb_pipe, X_test)\n",
    "stage1_contract_test.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec891b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>margin_%</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>prediction_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18467</th>\n",
       "      <td>18467</td>\n",
       "      <td>0</td>\n",
       "      <td>93.599998</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190998</th>\n",
       "      <td>190998</td>\n",
       "      <td>0</td>\n",
       "      <td>92.300003</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201522</th>\n",
       "      <td>201522</td>\n",
       "      <td>0</td>\n",
       "      <td>55.599998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302375</th>\n",
       "      <td>302375</td>\n",
       "      <td>0</td>\n",
       "      <td>96.800003</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84071</th>\n",
       "      <td>84071</td>\n",
       "      <td>0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296879</th>\n",
       "      <td>296879</td>\n",
       "      <td>0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107694</th>\n",
       "      <td>107694</td>\n",
       "      <td>0</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115683</th>\n",
       "      <td>115683</td>\n",
       "      <td>0</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140830</th>\n",
       "      <td>140830</td>\n",
       "      <td>0</td>\n",
       "      <td>70.699997</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285090</th>\n",
       "      <td>285090</td>\n",
       "      <td>0</td>\n",
       "      <td>74.699997</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9301</th>\n",
       "      <td>9301</td>\n",
       "      <td>0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116040</th>\n",
       "      <td>116040</td>\n",
       "      <td>0</td>\n",
       "      <td>91.099998</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300353</th>\n",
       "      <td>300353</td>\n",
       "      <td>0</td>\n",
       "      <td>98.400002</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19175</th>\n",
       "      <td>19175</td>\n",
       "      <td>0</td>\n",
       "      <td>91.599998</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132313</th>\n",
       "      <td>132313</td>\n",
       "      <td>0</td>\n",
       "      <td>98.599998</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-11-29 23:12:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  pred_class   margin_% uncertainty        prediction_ts\n",
       "18467       18467           0  93.599998         Low  2025-11-29 23:12:14\n",
       "190998     190998           0  92.300003         Low  2025-11-29 23:12:14\n",
       "201522     201522           0  55.599998      Medium  2025-11-29 23:12:14\n",
       "302375     302375           0  96.800003         Low  2025-11-29 23:12:14\n",
       "84071       84071           0  96.000000         Low  2025-11-29 23:12:14\n",
       "296879     296879           0  99.000000         Low  2025-11-29 23:12:14\n",
       "107694     107694           0  42.599998      Medium  2025-11-29 23:12:14\n",
       "115683     115683           0  97.900002         Low  2025-11-29 23:12:14\n",
       "140830     140830           0  70.699997         Low  2025-11-29 23:12:14\n",
       "285090     285090           0  74.699997         Low  2025-11-29 23:12:14\n",
       "9301         9301           0  94.000000         Low  2025-11-29 23:12:14\n",
       "116040     116040           0  91.099998         Low  2025-11-29 23:12:14\n",
       "300353     300353           0  98.400002         Low  2025-11-29 23:12:14\n",
       "19175       19175           0  91.599998         Low  2025-11-29 23:12:14\n",
       "132313     132313           0  98.599998         Low  2025-11-29 23:12:14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def stage1_predict_simple(df, model, id_col=None):\n",
    "    \"\"\"\n",
    "    Predict and summarize classification results in a minimal format.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): input features\n",
    "        model: fitted model with predict_proba\n",
    "        id_col (str, optional): column to use as patient ID\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame with prediction summary\n",
    "    \"\"\"\n",
    "    # Predict probabilities\n",
    "    P = model.predict_proba(df)             # shape (n_samples, n_classes)\n",
    "    \n",
    "    # Predicted class\n",
    "    pred_class = P.argmax(axis=1)\n",
    "    \n",
    "    # Margin as % for uncertainty\n",
    "    sortedP = np.sort(P, axis=1)[:, ::-1]\n",
    "    margin = (sortedP[:,0] - sortedP[:,1]) * 100\n",
    "    uncertainty = pd.cut(margin, bins=[-0.01, 30, 60, 100], labels=[\"High\", \"Medium\", \"Low\"])\n",
    "    \n",
    "    # Assemble output\n",
    "    out = pd.DataFrame({\n",
    "        \"pred_class\": pred_class,\n",
    "        \"margin_%\": margin.round(1),\n",
    "        \"uncertainty\": uncertainty,\n",
    "        \"prediction_ts\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }, index=df.index)\n",
    "    \n",
    "    # Insert patient ID if provided\n",
    "    if id_col and id_col in df.columns:\n",
    "        out.insert(0, \"patient_id\", df[id_col].values)\n",
    "    else:\n",
    "        out.insert(0, \"patient_id\", df.index.astype(str))\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Example usage\n",
    "stage1_summary = stage1_predict_simple(X_test,xgb_pipe )\n",
    "stage1_summary.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d13153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
